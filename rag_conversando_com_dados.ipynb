{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Loaders – Carregando dados com Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a lib necessária\n",
    "# para funcionar note também q é necessário ter a lib pypdf\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caminho para o arquivo\n",
    "caminho = 'contrato_aluguel_jose_nilton.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciando o carregador e fornecendo o caminho do arquivo pdf\n",
    "loader = PyPDFLoader(caminho)\n",
    "documentos = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veja que era um arquivo pdf pequeno\n",
    "# o carregamento deu somente 5 páginas\n",
    "len(documentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fazendo perguntas ao arquivo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a chain que permite fazermos as perguntas\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "# importando o modelo\n",
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciando o modelo para criar um chat\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando a chain\n",
    "# o chain_type é um tipo de retrieval q será explicado mais adiante\n",
    "chain = load_qa_chain(llm=chat, chain_type='stuff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = \"qual é o assunto do documento?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaio-peixoto/GitHub/asimov/aplicacoes-langchain/venv/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O documento apresentado é um Contrato de Locação Residencial.\n"
     ]
    }
   ],
   "source": [
    "# rodando a chain\n",
    "r = chain.run(input_documents=documentos, question=pergunta)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o processo é bem parecido com o do pdf\n",
    "# só temos q importar um loader diferente\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicando o caminho pro arquivo\n",
    "caminho_csv = 'Top 1000 IMDB movies.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando o csv\n",
    "loader_csv = CSVLoader(caminho_csv)\n",
    "docs_csv = loader_csv.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "': 0\\nMovie Name: The Shawshank Redemption\\nYear of Release: (1994)\\nWatch Time: 142 min\\nMovie Rating: 9.3\\nMeatscore of movie: 81\\nVotes: 34,709\\nGross: $28.34M\\nDescription: Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vendo o conteudo pra certificar q trata-se do csv mesmo\n",
    "docs_csv[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O faturamento dos filmes varia muito. O filme com o menor faturamento listado aqui é \"A Great Dictator,\" de 1940, com um faturamento de $0.29M.\n"
     ]
    }
   ],
   "source": [
    "# rodando a chain\n",
    "pergunta = \"tem aí o faturamento por filme? quem teve o menor?\"\n",
    "r = chain.run(input_documents=docs_csv[:100], question=pergunta)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando da Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YouTube\n",
    "\n",
    "Para executar essa tarefa é necessário a existência de 2 arquivos ffmpeg.exe e ffprobe.exe. Aqui vamos só dar o exemplo em códigos, mas sem executar. Os arquivos ffmpeg estão disponíveis na pasta do curso da Asimov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando as bibliotecas necessárias\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "yt_dlp package not found, please install it with `pip install yt_dlp`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/GitHub/asimov/aplicacoes-langchain/venv/lib/python3.8/site-packages/langchain_community/document_loaders/blob_loaders/youtube_audio.py:22\u001b[0m, in \u001b[0;36mYoutubeAudioLoader.yield_blobs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39myt_dlp\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yt_dlp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# construindo o loader\u001b[39;00m\n\u001b[1;32m      4\u001b[0m loader \u001b[39m=\u001b[39m GenericLoader(\n\u001b[1;32m      5\u001b[0m     YoutubeAudioLoader([url], save_dir),\n\u001b[1;32m      6\u001b[0m     OpenAIWhisperParser()\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m docs \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39;49mload()\n",
      "File \u001b[0;32m~/GitHub/asimov/aplicacoes-langchain/venv/lib/python3.8/site-packages/langchain_core/document_loaders/base.py:29\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m     28\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlazy_load())\n",
      "File \u001b[0;32m~/GitHub/asimov/aplicacoes-langchain/venv/lib/python3.8/site-packages/langchain_community/document_loaders/generic.py:115\u001b[0m, in \u001b[0;36mGenericLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlazy_load\u001b[39m(\n\u001b[1;32m    112\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    113\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Document]:\n\u001b[1;32m    114\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load documents lazily. Use this when working at a large scale.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mfor\u001b[39;00m blob \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblob_loader\u001b[39m.\u001b[39myield_blobs():  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    116\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblob_parser\u001b[39m.\u001b[39mlazy_parse(blob)\n",
      "File \u001b[0;32m~/GitHub/asimov/aplicacoes-langchain/venv/lib/python3.8/site-packages/langchain_community/document_loaders/blob_loaders/youtube_audio.py:24\u001b[0m, in \u001b[0;36mYoutubeAudioLoader.yield_blobs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39myt_dlp\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     25\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myt_dlp package not found, please install it with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`pip install yt_dlp`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     29\u001b[0m \u001b[39m# Use yt_dlp to download audio given a YouTube url\u001b[39;00m\n\u001b[1;32m     30\u001b[0m ydl_opts \u001b[39m=\u001b[39m {\n\u001b[1;32m     31\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mm4a/bestaudio/best\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnoplaylist\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     ],\n\u001b[1;32m     40\u001b[0m }\n",
      "\u001b[0;31mImportError\u001b[0m: yt_dlp package not found, please install it with `pip install yt_dlp`"
     ]
    }
   ],
   "source": [
    "url = 'https://www.youtube.com/watch?v=pszz9Xk_T2c' # link para o video do youtube\n",
    "save_dir = 'docs/youtube/' # diretorio onde o arquivo de audio transcrito ficará guardado\n",
    "# construindo o loader\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url], save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Executando o codigo acima ele vai transcrever o audio e guardar a informação. Daí ela já estará disponivel para ser integrada ao modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.web_base import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.aihr.com/blog/decision-trees-hr-analytics/'\n",
    "loader = WebBaseLoader(url)\n",
    "docs_url = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conteúdo do link fornecido é um guia prático sobre como usar árvores de decisão em análises de RH. O texto explica o que é uma árvore de decisão, quando utilizá-la em análises de RH, terminologia associada, exemplos de casos de uso, e como construir uma árvore de decisão. Ele fornece detalhes sobre como as árvores de decisão podem ser uma ferramenta valiosa para analistas de RH, especialmente na descoberta de padrões complexos em dados de RH.\n"
     ]
    }
   ],
   "source": [
    "# rodando a chain\n",
    "pergunta = \"qual o conteudo desse link q te passei?\"\n",
    "r = chain.run(input_documents=docs_url, question=pergunta)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Splitters\n",
    "\n",
    "Aqui o objetivo é dividir o documento em trechos menores para fornecer ao LLM apenas pedaços relevantes da informação e assim ele processar. Isso garante mais agilidade e precisão no resultado final.\n",
    "\n",
    "Mas como podemos manter a qualidade da informação se a dividimos em pedaços menores?\n",
    "\n",
    "Vejamos esta frase de exemplo: \"O novo carro da Fiat se chama Toro, tem 120 cavalos de potência e o preço sugerido é 135 mil reais.\"\n",
    "\n",
    "Digamos q o split dessa frase ficaria da seguinte forma:\n",
    "\n",
    "- \"O novo carro da Fiat se\"\n",
    "- \" chama Toro, tem 120 \"\n",
    "- \"cavalos de potência e \"\n",
    "- \"o preço sugerido é \"\n",
    "- \"135 mil reais.\"\n",
    "\n",
    "Aqui percebemos que os trechos separados individualmente não possuem valor. Sendo assim, seria de pouco valor para uma LLM, pois foi mal dividido.\n",
    "\n",
    "Uma das técnicas para resolver isso é usar o parametro do overlapping. Esta técnica faz com que cada chunk tenha um pedaço do chunk anterior e do próximo. Dessa forma o LLM flui pela informação podendo fazer ligações.\n",
    "\n",
    "Ficaria assim, por exemplo:\n",
    "\n",
    "- \"O novo carro da Fiat se\"\n",
    "- \"da Fiat se chama Toro, tem 120 \"\n",
    "- \"Toro, tem 120 cavalos de potência e \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esse é o texto q vamos splittar\n",
    "texto_grande = \"\"\"\n",
    "More and more organizations are turning to dashboards for monitoring performance and enabling data exploration. These user-friendly reporting tools offer a ton of advantages over older ways of doing things: they can dynamically update to display the latest information, link together multiple views of data, and often incorporate interactivity that lets users filter and zoom in on what they want to explore. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem formas diferentes de text splitter. Vamos explorar as mais utilizadas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o tamanho do chunk (fatias) que vc deseja dividir\n",
    "chunk_size = 50\n",
    "# o tamanho da sobreposição. Geralmente um tamanho de 10 a 20% do chunk já funciona\n",
    "chunk_overlap = 10\n",
    "\n",
    "# criando o objeto q irá fazer o split\n",
    "char_split = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator='' # o separator indica onde a divisão será feita\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos dar um exemplo de split com o abecedário\n",
    "# o abecedario está disponivel importando a lib string\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vamos criar nosso texto a ser dividido\n",
    "# pegamos o abecedario e o replicamos 5 vezes\n",
    "# veja q o tamanho do nosso texto ficou em 134 caracteres\n",
    "texto = '-'.join(f'{string.ascii_lowercase}' for _ in range(5))\n",
    "len(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz-abcdefghijklmnopqrstuvw',\n",
       " 'nopqrstuvwxyz-abcdefghijklmnopqrstuvwxyz-abcdefghi',\n",
       " '-abcdefghijklmnopqrstuvwxyz-abcdefghijklmnopqrstuv',\n",
       " 'mnopqrstuvwxyz']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agora fazendo o split do texto criado acima\n",
    "# veja q o tamanho ficou em 4, sendo o chunksize de 50 \n",
    "# e um total de 134 caracteres\n",
    "splits = char_split.split_text(texto)\n",
    "print(len(splits))\n",
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Veja acima como funciona o overlap. O segundo elemento da lista inicia com os 10 últimos caracteres da primeira lista, e assim sucessivamente. Ou seja, existe uma sobreposição entre o fim de um elemento da lista e inicio do próximo. A quantidade de caracteres que faz essa sobreposição é dada no chunk_overlap. E, claro, isso só não ocorre com o primeiro elemento, já q ele não tem antecessor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RecursiveCharacterTextSplitter**\n",
    "\n",
    "Esse é o mais utilizado, ele permite o uso de vários separadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 50\n",
    "chunk_overlap = 10\n",
    "\n",
    "# criando o objeto q irá fazer o split\n",
    "char_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vamos aproveitar o mesmo exemplo usado anteriormente\n",
    "texto = '-'.join(f'{string.ascii_lowercase}' for _ in range(5))\n",
    "len(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz-abcdefghijklmnopqrstuvw',\n",
       " 'nopqrstuvwxyz-abcdefghijklmnopqrstuvwxyz-abcdefghi',\n",
       " '-abcdefghijklmnopqrstuvwxyz-abcdefghijklmnopqrstuv',\n",
       " 'mnopqrstuvwxyz']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_split.split_text(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora utilizando o argumento separators\n",
    "\n",
    "Com este argumento o splitter cria uma ordem de prioridade para quebrar os chunks. No exemplo abaixo, primeiro ele quebra por ponto, depois por espaço vazio e depois por qualquer lugar do texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando o objeto q irá fazer o split\n",
    "char_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=['.', ' ', '']\n",
    ")\n",
    "\n",
    "# geralmente apenas uns poucos marcadores de split\n",
    "# são necessários. São eles: ['\\n\\n', '\\n', ' ', '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver um exemplo com um texto grande, com mais caracteres do que o abecedário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['More and more organizations are turning to',\n",
       " 'to dashboards for monitoring performance and',\n",
       " 'and enabling data exploration',\n",
       " '. These user-friendly reporting tools offer a ton',\n",
       " 'a ton of advantages over older ways of doing',\n",
       " 'of doing things: they can dynamically update to',\n",
       " 'update to display the latest information, link',\n",
       " 'link together multiple views of data, and often',\n",
       " 'and often incorporate interactivity that lets',\n",
       " 'that lets users filter and zoom in on what they',\n",
       " 'what they want to explore',\n",
       " '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_split.split_text(texto_grande)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TokenTextSplitter**\n",
    "\n",
    "Permite o fatiamento em tokens em vez de quantidade de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 50\n",
    "chunk_overlap = 10\n",
    "\n",
    "token_split = TokenTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz-abcdefghijklmnopqrstuvwxyz-abcdefghijklmnopqrstuvwxyz-abcdefghijkl',\n",
       " 'uvwxyz-abcdefghijklmnopqrstuvwxyz-abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_split.split_text(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Agora veja como fica a divisão por token. O abecedário agora foi dividido em apenas duas partes. Isso porque aquela primeira parte toda já é equivalente a 50 tokens. Essa forma de split facilita nosso gerenciamento das APIs da OpenAI e outras, que contabilizam o fluxo de dados em tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MarkdownHeaderTextSplitter**\n",
    "\n",
    "Podemos fazer o split de textos em Markdown. Existem vários marcadores nesse tipo de texto que podemos indicar para o split. Dessa forma fica mais fácil identificarmos quando trata-se de um texto principal (#), subtitulo (##), e etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_text = \"\"\"# Exemplo de titulo em markdown\n",
    "## Aqui é um subtitulo\n",
    "texto q fica dentro desse subtitulo\n",
    "### Aqui outra hierarquia de header\n",
    "Mais texto livre q fica dentro desta hierarquia\n",
    "**e vamos de mais exemplos**\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca necessária\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primeiro criamos uma lista de tuplas\n",
    "# onde terão os marcadores que farão o split\n",
    "\n",
    "header_to_split_on = [\n",
    "    ('#', 'Header 1'),\n",
    "    ('##', 'Header 2'),\n",
    "    ('###', 'Header 3'),\n",
    "]\n",
    "\n",
    "# criando o splitter\n",
    "md_split = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=header_to_split_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo o split\n",
    "splits = md_split.split_text(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='texto q fica dentro desse subtitulo', metadata={'Header 1': 'Exemplo de titulo em markdown', 'Header 2': 'Aqui é um subtitulo'}),\n",
       " Document(page_content='Mais texto livre q fica dentro desta hierarquia\\n**e vamos de mais exemplos**', metadata={'Header 1': 'Exemplo de titulo em markdown', 'Header 2': 'Aqui é um subtitulo', 'Header 3': 'Aqui outra hierarquia de header'})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Veja como fica o output. Ele traz as hierarquias de título\\subtitulo em metadata e traz seu conteúdo na variável page_content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texto q fica dentro desse subtitulo\n",
      "{'Header 1': 'Exemplo de titulo em markdown', 'Header 2': 'Aqui é um subtitulo'}\n",
      "===========\n",
      "Mais texto livre q fica dentro desta hierarquia\n",
      "**e vamos de mais exemplos**\n",
      "{'Header 1': 'Exemplo de titulo em markdown', 'Header 2': 'Aqui é um subtitulo', 'Header 3': 'Aqui outra hierarquia de header'}\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "# vamos deixar esse output mais claro\n",
    "# e vamos printar cada parte\n",
    "for doc in splits:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)\n",
    "    print(\"===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split de documentos**\n",
    "\n",
    "Vamos fazer o split de um documento, em vez de textos simples como fizemos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca q carregará e nos ajudará a trabalhar com doc\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# importando um splitter recursivo\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 50\n",
    "chunk_overlap = 10\n",
    "\n",
    "# criando o objeto q irá fazer o split\n",
    "# até aqui é identico ao q já fizemos anteriormente\n",
    "char_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caminho para o arquivo\n",
    "caminho = 'contrato_aluguel_jose_nilton.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregando o arquivo\n",
    "loader = PyPDFLoader(caminho)\n",
    "docs = loader.load()\n",
    "\n",
    "# veja que o tamanho é apenas 5, q é a quantidade de páginas\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agora vejamos depois de fazer o split\n",
    "# fique atento que aqui o método é diferente, sendo split_documents\n",
    "# em vez de split_text\n",
    "doc_split = char_split.split_documents(docs)\n",
    "len(doc_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings - Transformando texto em vetores\n",
    "\n",
    "Embeddings criam uma representação vetorial de um pedaço de texto. Ele transforma letras em números. Isso é útil, pois é assim que o modelo vai \"pensar\" de forma mais eficiente. Dessa forma ele pode buscar proximidades semanticas, etc. Os cálculos vetoriais é quem dão a \"consciencia\" e \"discernimento\" para o modelo.\n",
    "\n",
    "O Langchain fornece uma classe de embedding que interage com os modelos de embedding fornecidos no mercado, ou seja, existem ebeddings da OpenAI, HuggingFace, Claude etc. O Langchain fornece uma interface padrão para todas elas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o modelo default para embedding é esse q está no argumento da chamada\n",
    "# existem outros. Visite o site da OpenAI para detalhes\n",
    "# vamos instanciar esse embedding da OpenAI\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-ada-002')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding de Documentos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos criar nosso modelo \n",
    "# veja que ele possui uma lista, onde ficarão os documentos\n",
    "# inserimos 3 documentos, q no momento são apenas frases\n",
    "embeddings = embedding_model.embed_documents(\n",
    "    [\n",
    "        'Eu amo frutas!',\n",
    "        'Adoro comer maçã e morando no café da manhã',\n",
    "        'Eu não gostei dessa piada.'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temos 3 documentos\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.00657477715414702,\n",
       " -0.01645846854163768,\n",
       " 0.00858595778552882,\n",
       " -0.018020670716986154,\n",
       " 0.0003834389654492531,\n",
       " 0.012147038753740848,\n",
       " 0.0042468509564415,\n",
       " -0.016815192987670133,\n",
       " 0.020923658738159195,\n",
       " -0.018254386091060882]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vamos como ficou vetorizada a primeira frase\n",
    "# aqui vemos os 10 primeiros vetores\n",
    "embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0004073202309066271,\n",
       " 0.0022691385116755613,\n",
       " 0.010371467708254777,\n",
       " -0.010110052920248348,\n",
       " 0.0008906330637083648,\n",
       " 0.01609826783082426,\n",
       " -0.010243800151040828,\n",
       " -0.009763527358755165,\n",
       " 0.0037874703983525005,\n",
       " -0.0054045923240678955]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# como ficou a segunda...\n",
    "embeddings[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.007192779163206384,\n",
       " 0.010501820347042052,\n",
       " 0.02364119459212685,\n",
       " 0.005362824876373604,\n",
       " -0.01574063077795829,\n",
       " -0.00022685383203933346,\n",
       " 0.0016772059794873417,\n",
       " -0.016877924626423603,\n",
       " 0.01875325061971795,\n",
       " -0.015063094552185529]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e a terceira...\n",
    "embeddings[2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536 0.2231856932070314 -0.6502694359520379\n",
      "1536 0.2404526844552327 -0.6606612596653819\n",
      "1536 0.22455505498532602 -0.6345615833743852\n"
     ]
    }
   ],
   "source": [
    "# vamos fazer um for e analisar cada vetor\n",
    "# primeiro vemos q o tamanho dos vetores é o mesmo (1536)\n",
    "# isso acontece por causa do modelo escolhido da OpenAI, na hora de instanciar\n",
    "# depois pegamos o valor máximo e o mínimo de cada lista de vetores\n",
    "for emb in embeddings:\n",
    "    print(len(emb), max(emb), min(emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora vamos fazer uma multiplicação vetorial utilizando o numpy\n",
    "# para identificarmos as semelhanças semanticas entre os vetores\n",
    "# é através desses cálculo que o modelo 'pensa' e sabe das semelhanças\n",
    "# entre as frases\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8840208063954538"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiplicando a primeira e a segunda frase\n",
    "# veja o número que obtemos\n",
    "# quanto mais alto significa que as frases tem semânticas próximas\n",
    "np.dot(embeddings[0], embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7906236951124648"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agora veja a comparação da frase 1 com a frase 3, o número é menor\n",
    "np.dot(embeddings[0], embeddings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7688656058169998"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mesma coisa entre as frases 2 e 3\n",
    "np.dot(embeddings[1], embeddings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 | 0.884 | 0.791 | \n",
      "0.884 | 1.0 | 0.769 | \n",
      "0.791 | 0.769 | 1.0 | \n"
     ]
    }
   ],
   "source": [
    "# vamos ver o conjunto todo, multiplicando todos vetores entre eles\n",
    "for i in range(len(embeddings)):\n",
    "    for j in range(len(embeddings)):\n",
    "        print(round(np.dot(embeddings[i], embeddings[j]), 3), end=' | ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding Query**\n",
    "\n",
    "Precisamos tbm fazer o embedding da pergunta do usuário ao modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.011808570584532625,\n",
       " -0.001554366564906917,\n",
       " 0.003285103508179982,\n",
       " -0.0045724423097403,\n",
       " 0.003168072813870247,\n",
       " 0.0044142031522565305,\n",
       " -0.008650387718005114,\n",
       " -0.0342059548409562,\n",
       " -0.01714253627852646,\n",
       " 0.003685645560653512]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pergunta = \"quais os alimentos mais saudáveis\"\n",
    "emb_query = embedding_model.embed_query(pergunta)\n",
    "emb_query[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8124131758838706"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agora comparando com as frases criadas antes\n",
    "# veja como a pergunta é próxima das frase 1 por exemplo\n",
    "np.dot(emb_query, embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7236383196137155"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e veja com ela é mais distante da frase 3\n",
    "np.dot(emb_query, embeddings[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding com Huggingface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.huggingface import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaio-peixoto/GitHub/asimov/aplicacoes-langchain/venv/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/kaio-peixoto/GitHub/asimov/aplicacoes-langchain/venv/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "emb_model = HuggingFaceBgeEmbeddings(model_name=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = emb_model.embed_documents(\n",
    "    [\n",
    "    'Eu amo frutas!',\n",
    "    'Adoro comer maçã e morango no café da manhã',\n",
    "    'A crise financeira de 2008 abalou o mundo.']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 | 0.348 | 0.413 | \n",
      "0.348 | 1.0 | 0.315 | \n",
      "0.413 | 0.315 | 1.0 | \n"
     ]
    }
   ],
   "source": [
    "# vamos ver o conjunto todo, multiplicando todos vetores entre eles\n",
    "for i in range(len(embeddings)):\n",
    "    for j in range(len(embeddings)):\n",
    "        print(round(np.dot(embeddings[i], embeddings[j]), 3), end=' | ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VectorStores\n",
    "\n",
    "Uma VectorStore faz o armazenamento de vetores e realiza a busca desses vetores. Depois de fazermos o embedding, como explicado na aula anterior, temos que guardá-los num lugar otimizado para trabalharmos com os vetores.\n",
    "\n",
    "Temos várias soluções d VectorStores e aqui vamos estudar duas das mais utilizadas: Chroma e FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chroma VectorStore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos fazer o processo desde o início\n",
    "# ou seja, vamos carregar os documentos, splittar, fazer o embedding\n",
    "# e guardar na VectorStore para retrieval\n",
    "\n",
    "# importando as libs para carregar os docs\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando os documentos\n",
    "caminho = 'contrato_aluguel_jose_nilton.pdf'\n",
    "loader = PyPDFLoader(caminho)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora vamos para o text splitting\n",
    "recur_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=250,\n",
    "    chunk_overlap=30,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "documents = recur_split.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando a VectorStore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio = \"files/chroma_vectorstore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings_model,\n",
    "    persist_directory=diretorio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
